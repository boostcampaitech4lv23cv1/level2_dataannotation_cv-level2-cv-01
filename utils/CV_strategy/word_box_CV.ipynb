{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split,StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    with Path(filename).open(encoding='utf8') as handle:\n",
    "        ann = json.load(handle)\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICDAR_data = read_json(\"/opt/ml/input/data/ICDAR17_Korean/ufo/train.json\")\n",
    "UPSTAGE_data = read_json(\"/opt/ml/input/data/upstage/ufo/annotation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_size(quads):\n",
    "    \"\"\" 단어 영역의 사각형 좌표가 주어졌을 때 가로, 세로길이를 계산해주는 함수.\n",
    "    TODO: 각 변의 길이를 단순히 max로 처리하기때문에 직사각형에 가까운 형태가 아니면 약간 왜곡이 있다.\n",
    "    Args:\n",
    "        quads: np.ndarray(n, 4, 2) n개 단어 bounding-box의 4개 점 좌표 (단위 pixel)\n",
    "    Return:\n",
    "        sizes: np.ndarray(n, 2) n개 box의 (height, width)쌍\n",
    "    \"\"\"\n",
    "    dists = []\n",
    "    for i, j in [(1, 2), (3, 0), (0, 1), (2, 3)]: # [right(height), left(height), upper(width), lower(width)] sides\n",
    "        dists.append(np.linalg.norm(quads[:, i] - quads[:, j], ord=2, axis=1))\n",
    "\n",
    "    dists = np.stack(dists, axis=-1).reshape(-1, 2, 2) # shape (n, 2, 2) widths, heights into separate dim\n",
    "    return np.rint(dists.mean(axis=-1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_poly(poly, direction, img_w, img_h):\n",
    "    \"\"\"일반 polygon형태인 라벨을 크롭하고 rectify해주는 함수.\n",
    "    Args:\n",
    "        poly: np.ndarray(2n+4, 2) (where n>0), 4, 6, 8\n",
    "        image: np.ndarray opencv 포멧의 이미지\n",
    "        direction: 글자의 읽는 방향과 진행 방향의 수평(Horizontal) 혹은 수직(Vertical) 여부\n",
    "    Return:\n",
    "        rectified: np.ndarray(2, ?) rectify된 단어 bbox의 사이즈.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_pts = poly.shape[0]\n",
    "    assert n_pts % 2 == 0\n",
    "    if n_pts == 4:\n",
    "        size = get_box_size(poly[None])\n",
    "        h = size[:, 0] / img_h\n",
    "        w = size[:, 1] / img_w\n",
    "        return np.stack((h,w))\n",
    "\n",
    "    def unroll(indices):\n",
    "        return list(zip(indices[:-1], indices[1:]))\n",
    "\n",
    "    # polygon하나를 인접한 사각형 여러개로 쪼갠다.\n",
    "    indices = list(range(n_pts))\n",
    "    if direction == 'Horizontal':\n",
    "        upper_pts = unroll(indices[:n_pts // 2]) # (0, 1), (1, 2), ... (4, 5)\n",
    "        lower_pts = unroll(indices[n_pts // 2:])[::-1] # (8, 9), (7, 8), ... (6, 7)\n",
    "\n",
    "        quads = np.stack([poly[[i, j, k, l]] for (i, j), (k, l) in zip(upper_pts, lower_pts)])\n",
    "    else:\n",
    "        right_pts = unroll(indices[1:n_pts // 2 + 1]) # (1, 2), (2, 3), ... (4, 5)\n",
    "        left_pts = unroll([0] + indices[:n_pts // 2:-1]) # (0, 9), (9, 8), ... (7, 6)\n",
    "\n",
    "        quads = np.stack([poly[[i, j, k, l]] for (j, k), (i, l) in zip(right_pts, left_pts)])\n",
    "\n",
    "    sizes = get_box_size(quads)\n",
    "    if direction == 'Horizontal':\n",
    "        h = sizes[:, 0].max() / img_h\n",
    "        widths = sizes[:, 1]\n",
    "        w = np.sum(widths) / img_w\n",
    "        return np.stack((h,w)).reshape(2,-1)\n",
    "        #return np.stack((h,w))\n",
    "    elif direction == 'Vertical':\n",
    "        heights = sizes[:, 0]\n",
    "        w = sizes[:, 1].max() / img_w\n",
    "        h = np.sum(heights) / img_h\n",
    "        return np.stack((h,w)).reshape(2,-1)\n",
    "    else:\n",
    "        h = sizes[:, 0] / img_h\n",
    "        w = sizes[:, 1] / img_w\n",
    "        return np.stack((h,w),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_df(data):   \n",
    "    df = dict()\n",
    "    df['image'] = deque()\n",
    "    df['word_counts'] = deque()\n",
    "    df['image_width'] = deque()\n",
    "    df['image_height'] = deque()\n",
    "    df['image_tags'] = deque()\n",
    "    img_tags = deque()\n",
    "\n",
    "    quads = deque()\n",
    "    polys = deque()\n",
    "    seq_length = deque()\n",
    "    hor_sizes = deque()\n",
    "    ver_sizes = deque()\n",
    "    irr_sizes = deque()\n",
    "    languages = deque()\n",
    "    orientation = deque()\n",
    "    word_tags = deque()\n",
    "    aspect_ratio = deque()\n",
    "    ver_string = deque()\n",
    "\n",
    "    for image_key, image_value in tqdm(data[\"images\"].items()):\n",
    "        df['image'].append(image_key)\n",
    "        img_w = image_value['img_w']\n",
    "        img_h = image_value['img_h']\n",
    "        df['image_width'].append(img_w)\n",
    "        df['image_height'].append(img_h)\n",
    "        df['image_tags'].append(image_value['tags'])\n",
    "        df['image_tags']= [['None'] if v is None else v for v in df['image_tags']] # our data does not inlcude multi-tag images \n",
    "        word_ann = image_value['words']\n",
    "        count_ill = 0 \n",
    "        for word in word_ann.values():\n",
    "            if word['illegibility']== False:\n",
    "                orientation.append(word['orientation'])\n",
    "                orientation = [v for v in orientation]\n",
    "                seq_length.append(len(word['transcription']))\n",
    "                languages.append(word['language'])\n",
    "                languages = [['None'] if v is None else v for v in languages] # our data does not inlcude multi-language words\n",
    "                if word['tags'] != None:\n",
    "                    word_tags.extend(word['tags'][:])\n",
    "                elif word['tags']== None:\n",
    "                    word_tags.append('None')\n",
    "                poly = np.int32(word['points'])\n",
    "                size = rectify_poly(poly, word['orientation'], img_w, img_h)\n",
    "                if word['orientation'] == 'Horizontal':\n",
    "                    hor_sizes.append(size)\n",
    "                elif word['orientation'] == 'Vertical':\n",
    "                    ver_sizes.append(size)\n",
    "                else:\n",
    "                    irr_sizes.append(size)\n",
    "                \n",
    "            else:\n",
    "                count_ill += 1\n",
    "        df['word_counts'].append(len(word_ann)-count_ill)\n",
    "\n",
    "            \n",
    "    all_sizes = hor_sizes + ver_sizes + irr_sizes\n",
    "    quad_area = [all_sizes[i][0]*all_sizes[i][1] for i in range(len(all_sizes))]\n",
    "    total_area = deque()\n",
    "    for s in quad_area:\n",
    "        if s.shape[0] == 1:\n",
    "            total_area.append(np.sum(s[0])) \n",
    "        else:\n",
    "            total_area.append(np.sum(s))\n",
    "\n",
    "    hor_aspect_ratio = [hor_sizes[i][1]/hor_sizes[i][0] for i in range(len(hor_sizes))]\n",
    "    ver_aspect_ratio = [ver_sizes[i][1]/ver_sizes[i][0] for i in range(len(ver_sizes))]\n",
    "    image_df = pd.DataFrame.from_dict(df)\n",
    "    return image_df "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기부터 시작\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_word_counts_amount_to_df():\n",
    "    _25percent = ICDAR_image_df.describe().word_counts.loc['25%']\n",
    "    _50percent = ICDAR_image_df.describe().word_counts.loc['50%']\n",
    "    _75percent = ICDAR_image_df.describe().word_counts.loc['75%']\n",
    "\n",
    "    _33percent = (_25percent+_50percent)/2\n",
    "    _66percent = (_50percent+_75percent)/2\n",
    "    ICDAR_image_df['word_counts_amount'] = np.where(ICDAR_image_df[\"word_counts\"] <= _33percent, 'few',\n",
    "                                                np.where(ICDAR_image_df[\"word_counts\"]<=_66percent,'normal','many'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ratio_and_dump(cv): \n",
    "    cv=cv\n",
    "    var = [(ICDAR_image_df.loc[idx,'image'], ICDAR_image_df.loc[idx,'word_counts_amount']) for idx in range(len(ICDAR_image_df))]\n",
    "\n",
    "    X = np.ones((len(var), ))\n",
    "    y = np.array([v[1] for v in var])\n",
    "    groups = np.array([v[0] for v in  var])\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X, y, groups):\n",
    "        print(\"TRAIN:\", groups[train_idx])\n",
    "        print(\"      \", y[train_idx])\n",
    "        print(\"TEST :\", groups[test_idx])\n",
    "        print(\"      \", y[test_idx])\n",
    "        \n",
    "    amounts = ['few','normal','many']\n",
    "    wd = {'few': 0, 'many': 1, 'normal': 2}\n",
    "    # check distribution\n",
    "    def get_distribution(y):\n",
    "        y_distr = Counter(y)\n",
    "        y_vals_sum = sum(y_distr.values())\n",
    "        \n",
    "        return [f'{y_distr[i]/y_vals_sum:.2%}'  for i in amounts]\n",
    "        \n",
    "    distrs = [get_distribution(y)]\n",
    "    index = ['training set']\n",
    "\n",
    "    for fold_ind, (train_idx, val_idx) in enumerate(cv.split(X,y, groups)):\n",
    "        train_y, val_y = y[train_idx], y[val_idx]\n",
    "        train_gr, val_gr = groups[train_idx], groups[val_idx]\n",
    "        \n",
    "        assert len(set(train_gr) & set(val_gr)) == 0\n",
    "        \n",
    "        distrs.append(get_distribution(train_y))\n",
    "        distrs.append(get_distribution(val_y))\n",
    "        \n",
    "        index.append(f'train - fold{fold_ind}')\n",
    "        index.append(f'val - fold{fold_ind}')\n",
    "                    \n",
    "    categories = [d for d in wd.keys()]\n",
    "\n",
    "    print(pd.DataFrame(distrs, index=index, columns = [amounts[i] for i in range(3)]))\n",
    "\n",
    "    for idx, (train_idx, valid_idx) in enumerate(cv.split(X,y, groups)):\n",
    "        ICDAR_train_fold = dict(); ICDAR_valid_fold = dict()\n",
    "        ICDAR_train_fold['images']={}; ICDAR_valid_fold['images']={}\n",
    "        \n",
    "        for i in range(len(groups[train_idx])):\n",
    "            ICDAR_train_fold['images'][groups[train_idx][i]] = ICDAR_data['images'][groups[train_idx][i]]\n",
    "\n",
    "        for i in range(len(groups[valid_idx])):\n",
    "            ICDAR_valid_fold['images'][groups[valid_idx][i]] = ICDAR_data['images'][groups[valid_idx][i]]\n",
    "        \n",
    "        \n",
    "        with open(f'../../../input/data/ICDAR19/ufo/ICDAR19_{language}_train_fold{idx}.json', 'w') as f:\n",
    "            json.dump(ICDAR_train_fold, f, indent = 4)\n",
    "\n",
    "        with open(f'../../../input/data/ICDAR19/ufo/ICDAR19_{language}_valid_fold{idx}.json', 'w') as f:\n",
    "            json.dump(ICDAR_valid_fold, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9996/9996 [17:57<00:00,  9.27it/s]  \n",
      "/tmp/ipykernel_6325/1760420105.py:66: RuntimeWarning: invalid value encountered in true_divide\n",
      "  hor_aspect_ratio = [hor_sizes[i][1]/hor_sizes[i][0] for i in range(len(hor_sizes))]\n",
      "/tmp/ipykernel_6325/1760420105.py:66: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  hor_aspect_ratio = [hor_sizes[i][1]/hor_sizes[i][0] for i in range(len(hor_sizes))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: ['tr_img_00002.jpg' 'tr_img_00004.jpg' 'tr_img_00005.jpg' ...\n",
      " 'tr_img_09996.jpg' 'tr_img_09998.jpg' 'tr_img_10000.jpg']\n",
      "       ['normal' 'normal' 'few' ... 'few' 'few' 'normal']\n",
      "TEST : ['tr_img_00001.jpg' 'tr_img_00003.jpg' 'tr_img_00006.jpg' ...\n",
      " 'tr_img_09995.jpg' 'tr_img_09997.jpg' 'tr_img_09999.jpg']\n",
      "       ['many' 'normal' 'few' ... 'normal' 'normal' 'normal']\n",
      "TRAIN: ['tr_img_00001.jpg' 'tr_img_00003.jpg' 'tr_img_00006.jpg' ...\n",
      " 'tr_img_09995.jpg' 'tr_img_09997.jpg' 'tr_img_09999.jpg']\n",
      "       ['many' 'normal' 'few' ... 'normal' 'normal' 'normal']\n",
      "TEST : ['tr_img_00002.jpg' 'tr_img_00004.jpg' 'tr_img_00005.jpg' ...\n",
      " 'tr_img_09996.jpg' 'tr_img_09998.jpg' 'tr_img_10000.jpg']\n",
      "       ['normal' 'normal' 'few' ... 'few' 'few' 'normal']\n",
      "                  few  normal    many\n",
      "training set   42.03%  25.30%  32.67%\n",
      "train - fold0  42.18%  25.29%  32.53%\n",
      "val - fold0    41.88%  25.31%  32.81%\n",
      "train - fold1  41.88%  25.31%  32.81%\n",
      "val - fold1    42.18%  25.29%  32.53%\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedGroupKFold(n_splits=2, shuffle = True, random_state=2022)\n",
    "languages=['Latin','Arabic','Symbols','None','Chinese','Mixed','Japanese','Korean','Bangla','Hindi']\n",
    "\n",
    "language='Total'\n",
    "ICDAR_data = read_json(f'../../../input/data/ICDAR19/ufo/ICDAR19_{language}.json')\n",
    "ICDAR_image_df = making_df(ICDAR_data)\n",
    "add_word_counts_amount_to_df()\n",
    "check_ratio_and_dump(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    language = languages[idx]\n",
    "    ICDAR_data = read_json(f\"../../../input/data/ICDAR19/ufo/ICDAR19_{language}.json\")\n",
    "    ICDAR_image_df = making_df(ICDAR_data)\n",
    "    add_word_counts_amount_to_df()\n",
    "    check_ratio_and_dump(cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge df 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.concat([ICDAR_image_df,UPSTAGE_image_df])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('annotation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c227b641af2a075e7651d698322facbbba7e7ad5ccfcb7775dbbc0e4e14b54e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
